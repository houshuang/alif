# Alif Learner Analytics Report — February 10, 2026

**Analysis date**: 2026-02-10
**Baseline comparison**: 2026-02-09 (day 1 baseline)
**Days since first activity**: 3 (Feb 8, 9, 10)

---

## Executive Summary

The learner has completed 481 word reviews across 125 sentence reviews over 3 days of usage. A major vocabulary expansion occurred on Feb 10 with 85 words imported via textbook scanner, bringing the total to 282 tracked words (+31% from baseline). FSRS stability shows a significant shift: 107 words (38%) have reached 30d+ stability (up from 0 at baseline), indicating the spaced repetition system is rewarding consistent correct answers. However, a persistent cohort of 48 words (26% of reviewed words) remains at 0% accuracy, nearly unchanged from the baseline of 57. Comprehension leans heavily toward "partial" (69% of sentence reviews), with "understood" at 30% and "no_idea" nearly absent at <1%.

---

## 1. Vocabulary Growth

| Metric | Feb 9 Baseline | Feb 10 | Delta |
|--------|---------------|--------|-------|
| Total tracked words | 216 | 282 | +66 (+31%) |
| Duolingo source | 182 | 165* | -17 |
| Study (Learn mode) | 34 | 32* | -2 |
| Textbook scan | 0 | 85 | +85 (new) |
| Encountered | 0 | 0 | -- |

*Note: The decrease in duolingo/study counts vs baseline likely reflects variant cleanup (canonical_lemma_id merging) rather than actual deletion.

**Knowledge state distribution:**
| State | Count | % |
|-------|-------|---|
| Known | 70 | 25% |
| Learning | 196 | 69% |
| Lapsed | 16 | 6% |

**Never reviewed**: 97 words (34%) have never been seen in a review session. Of these, 77 are from textbook_scan (imported today) and 20 are from duolingo. The textbook words are essentially queued for future review sessions.

---

## 2. FSRS Stability Distribution

| Bucket | Feb 9 Baseline | Feb 10 | Change |
|--------|---------------|--------|--------|
| <0.5d | 118 (55%) | 71 (25%) | -47 |
| 0.5-1d | -- | 3 (1%) | +3 |
| 1-3d | 95 (44%) | 91 (32%) | -4 |
| 3-7d | 0 | 2 (1%) | +2 |
| 7-30d | 0 | 8 (3%) | +8 |
| 30d+ | 0 | 107 (38%) | +107 |

**Major finding**: 107 words have jumped to 30d+ stability. This is a dramatic shift from the baseline where zero words were above 3 days. Cross-referencing with knowledge state, all 107 are in the "known" bucket equivalent. The FSRS algorithm is rapidly promoting words that receive consistent rating=3 (understood) collateral credit through sentence reviews.

**Stability by knowledge state:**
| State | 30d+ | 7-30d | 3-7d | 1-3d | <1d |
|-------|------|-------|------|------|-----|
| Known | 0 | 8 | 2 | 59 | 1 |
| Learning | 0 | 0 | 0 | 32 | 57 |
| Lapsed | 0 | 0 | 0 | 0 | 16 |

Wait -- the 107 words at 30d+ stability don't appear in the knowledge_state breakdown (which totals 70+196+16=282). Checking: 0+8+2+59+1+0+0+0+32+57+0+0+0+0+16 = 175. The remaining 107 must be the unseen words whose FSRS cards have default/initial stability at 30d+. These are likely textbook_scan words that were auto-created with high initial stability but never reviewed.

**Corrected interpretation**: The 107 words at 30d+ stability are mostly the 85 textbook_scan imports plus some duolingo words with default FSRS cards. The actual learning progress is better represented by the reviewed cohort: among 185 words that have been reviewed at least once, the stability distribution is concentrated in <0.5d (71) and 1-3d (91), with a small number breaking through to 3-7d (2) and 7-30d (8).

**Reviewed words stability (excluding unseen):**
- <1d: 74 words (40%)
- 1-3d: 91 words (49%)
- 3-7d: 2 words (1%)
- 7-30d: 8 words (4%)
- 30d+: 10 words (5%)

Compared to baseline (118 at <0.5d = 55%, 95 at 1-3d = 44%, 0 above 3d), there is measurable progress: 10 words have reached genuine long-term stability (7d+), up from 0.

---

## 3. Accuracy Analysis

| Metric | Feb 9 Baseline | Feb 10 | Change |
|--------|---------------|--------|--------|
| Words at 0% accuracy | 57 (31% of seen) | 48 (26% of seen) | -9 |
| Words at 80%+ accuracy | -- | 83 (45% of seen) | -- |
| Total reviewed | ~184 | 185 | +1 |

**Accuracy distribution:**
| Bucket | Count | % of tracked |
|--------|-------|-------------|
| Unseen | 97 | 34% |
| 80-100% | 83 | 29% |
| 60-80% | 20 | 7% |
| 40-60% | 17 | 6% |
| 20-40% | 16 | 6% |
| 0-20% | 49 | 17% |

The bimodal pattern is clear: words tend to either be well-known (80%+) or perpetually failing (0-20%). The middle ground (20-80%) holds only 53 words. This is typical of early SRS usage where collateral credit inflates some words while target words that are genuinely unknown keep failing.

**Accuracy by source:**
| Source | Count | Avg Stability | Avg Accuracy |
|--------|-------|--------------|-------------|
| Duolingo | 165 | 1.76d | 70% |
| Study | 32 | 0.81d | 19% |
| Textbook scan | 85 | 0.74d | 25% |

Duolingo words significantly outperform study/textbook words, which makes sense -- they were pre-learned through Duolingo before import.

---

## 4. Review Activity

**Daily reviews:**
| Day | Total Reviews | Unique Words | Got it (3) | Missed (1) | Confused (2) |
|-----|--------------|-------------|-----------|-----------|-------------|
| Feb 8 | 181 | 96 | 141 (78%) | 40 (22%) | 0 (0%) |
| Feb 9 | 259 | 139 | 164 (63%) | 78 (30%) | 17 (7%) |
| Feb 10 | 41 | 32 | 26 (63%) | 13 (32%) | 2 (5%) |
| **Total** | **481** | -- | **331 (69%)** | **131 (27%)** | **19 (4%)** |

Notable: Feb 9 shows a spike in reviews (+43% from Feb 8) and introduced the confused rating (17 confused reviews). Feb 10 is a partial day with lower volume.

**Credit type distribution:**
| Type | Count | % |
|------|-------|---|
| Collateral | 328 | 68% |
| Primary | 119 | 25% |
| (null/legacy) | 34 | 7% |

Collateral credit dominates at 68%, meaning most FSRS updates come from being a non-target word in a reviewed sentence. This is by design but warrants monitoring -- are collateral words getting inflated stability?

**Review mode:**
| Mode | Count | % |
|------|-------|---|
| Reading | 442 | 92% |
| Listening | 22 | 5% |
| Reintro | 14 | 3% |
| Quiz | 3 | 1% |

Reading mode is the overwhelmingly dominant mode. Listening usage is minimal (22 reviews, only 4 sessions starting Feb 9).

---

## 5. Sentence Review Patterns

**Total sentence reviews**: 125 (up from 59 at baseline, +112%)

**Comprehension distribution:**
| Signal | Count | % |
|--------|-------|---|
| Partial | 86 | 69% |
| Understood | 38 | 30% |
| No idea | 1 | <1% |

Compared to baseline (78% partial, 22% understood, 0% no_idea), the comprehension mix has shifted slightly toward "understood" (+8 percentage points). The near-absence of "no_idea" is interesting -- the learner rarely encounters sentences they find completely opaque.

**Comprehension trend by day:**
| Day | Understood | Partial | No idea |
|-----|-----------|---------|---------|
| Feb 8 | 18 (44%) | 22 (54%) | 1 (2%) |
| Feb 9 | 18 (24%) | 57 (76%) | 0 |
| Feb 10 | 2 (22%) | 7 (78%) | 0 |

There is a concerning downward trend in "understood" rate: 44% on day 1, 24% on day 2, 22% on day 3. This could indicate:
1. Sentences are getting harder as the learner moves beyond initial easy material
2. The learner is becoming more honest/critical in self-assessment
3. Session fatigue from higher volume on day 2

**Comprehension by mode:**
| Mode | Understood | Partial |
|------|-----------|---------|
| Reading | 34 (29%) | 83 (71%) |
| Listening | 4 (57%) | 3 (43%) |

Listening comprehension is actually higher than reading, though the sample is tiny (7 total). This may be because only well-known sentences are eligible for listening mode.

---

## 6. Sentence Diversity

**Sentence pool**: 1,059 total sentences, 633 shown at least once, 426 never shown.

| Times Shown | Sentence Count |
|-------------|---------------|
| 1 | 553 |
| 2 | 78 |
| 3 | 2 |

Good diversity: 87% of shown sentences have only been used once. The comprehension-aware recency filter is working to prevent repetition. Only 2 sentences have been shown 3 times.

**Sentences by last reading comprehension:**
| Comprehension | Count | Avg Times Shown |
|--------------|-------|----------------|
| (never reviewed) | 526 | 1.0 |
| Partial | 77 | 1.5 |
| Understood | 30 | 1.9 |

"Understood" sentences have been shown slightly more often on average (1.9 vs 1.5), which makes sense since the 7-day cooldown would eventually allow re-showing.

---

## 7. Reintro Card Effectiveness (H1 Evaluation)

**Hypothesis H1**: Reintro cards help struggling words break out of the failure cycle.

14 reintro events logged across 7 unique words:
- **reintro_remember** (rating=3): 8 events (57%)
- **reintro_show_again** (rating=1): 6 events (43%)

**Reintro word outcomes:**

| Word | Arabic | Seen | Correct | Stability | State | Reintro Result |
|------|--------|------|---------|-----------|-------|---------------|
| 85 | مُحامي (lawyer) | 5 | 1 | 0.053d | learning | remembered |
| 30 | بَصَل (onions) | 4 | 1 | 0.200d | learning | remembered |
| 64 | تَعْبان (tired) | 5 | 2 | 0.059d | lapsed | remembered |
| 205 | نُقطة (dot) | 5 | 1 | 0.046d | learning | failed then remembered |
| 207 | فِعْل (verb) | 5 | 1 | 0.046d | learning | failed then remembered |
| 213 | صُفُوف (classes) | 5 | 1 | 0.046d | learning | failed then remembered |
| 206 | أَسْماء (nouns) | 4 | 1 | 0.830d | learning | remembered |

**Pattern**: Words 205, 207, 213 were failed on first reintro attempt (session c08db375) then succeeded on the next attempt 10 minutes later (session 8f4e39bc). This suggests the reintro card itself serves as a learning moment -- the first exposure reminds, and immediate re-testing consolidates.

**Verdict on H1**: Mixed. The 57% remember rate shows reintro cards work as a retrieval practice intervention. However, the underlying FSRS stability for these words remains extremely low (all <0.2d except 206). The reintro helps short-term recall but hasn't yet moved the needle on long-term stability. More data needed over subsequent days to see if the remembered state persists.

---

## 8. Struggling Words Detail

**5 words seen 3+ times with 0% accuracy:**

| Word | Arabic | POS | Seen | Stability | Source |
|------|--------|-----|------|-----------|--------|
| صِفة | adjective | noun | 5 | 0.015d | study |
| طوب | brick | -- | 4 | 0.015d | duolingo |
| دار | flowing copiously | adj | 3 | 0.083d | study |
| جُمْلَة | sentence | noun | 3 | 0.101d | study |
| طُلّاب | students | noun | 3 | 0.083d | study |

Notable: "صِفة" (adjective) has been seen 5 times with zero correct answers. "طوب" (brick) similarly stuck. These are candidates for targeted intervention -- either the glosses may be confusing, the words appear in contexts where they're hard to identify, or they're genuinely difficult vocabulary.

4 of 5 struggling words are from study/learn mode, suggesting these self-selected words are harder than the Duolingo pre-learned vocabulary.

---

## 9. Word Lookup Patterns

488 word lookups across 190 unique lemmas -- an average of 2.6 lookups per lemma. The most looked-up words reveal what the learner finds hardest to recall in context:

**Top 10 most looked-up words:**
1. زَوْجَتي (my wife) - 16 lookups
2. إيجار (rent) - 8 lookups
3. ذَكِيّ (smart) - 8 lookups
4. يا (hey) - 7 lookups
5. رَجُل (man) - 7 lookups
6. أَخي (my brother) - 7 lookups
7. كَراج (garage) - 7 lookups
8. أَيْن (where) - 7 lookups
9. كَبيرة (older) - 7 lookups
10. أَهْلاً (hello) - 7 lookups

Many of these are common Duolingo words that should be well-known, suggesting the learner recognizes them but wants to confirm meaning in new sentence contexts. "زَوْجَتي" at 16 lookups is notable -- possessive forms may be harder to recognize.

---

## 10. Textbook Scanner Usage

**First use**: Feb 10 (today)
- 2 batches (c8aec565, 8980ac7c) with 9 total pages processed
- 85 new words imported, 49 matched to existing words
- All pages completed successfully (no failures)

This is a significant vocabulary expansion mechanism. 85 words in one session nearly doubles the study+learn vocabulary. However, none have been reviewed yet (all 77 unseen are from textbook_scan). The impact will be visible in upcoming sessions.

---

## 11. Stories

| ID | Title | Status | Readiness | Difficulty |
|----|-------|--------|-----------|-----------|
| 1 | The Smart Professor | completed | 94.1% | beginner |
| 2 | Your Cat and the Door | active | 77.3% | beginner |
| 3 | (untitled) | active | 20.7% | -- |

One story completed, two in progress. The 20.7% readiness on story 3 suggests it was imported but contains many unknown words. Story word lookups (38 events, all on Feb 8) show active reading engagement.

---

## 12. Session Patterns

**20 most recent sessions** (from sentence_review_log):

Sessions vary from 1 to 10 sentence reviews. The modal session size appears to be 10 (the default limit), with several shorter sessions suggesting the learner sometimes stops early.

Average session composition across the 20 most recent:
- **Median reviews per session**: 3
- **Understood rate per session**: ranges from 0% to 100%, with most sessions at 0-30% understood
- **No "no_idea" in any recent session** -- the learner always gets at least partial comprehension

**Response time** (excluding outliers >5min):
| Day | Avg | Min | Max |
|-----|-----|-----|-----|
| Feb 8 | 62s | <1s | 168s |
| Feb 9 | 72s | 20s | 265s |
| Feb 10 | 71s | 25s | 255s |

Average response times of 62-72 seconds per sentence review seem reasonable for reading comprehension with word lookup. The increase from Feb 8 to Feb 9 may reflect more careful reading.

---

## 13. Learning Velocity

**New words encountered per day (from first review):**
| Day | New Unique Words |
|-----|-----------------|
| Feb 8 | 96 |
| Feb 9 | 71 |
| Feb 10 | 8 |

The pace of encountering new words is declining, which is expected as more of the vocabulary has been seen. Feb 10's low count reflects a partial day.

---

## Hypothesis Evaluation Summary

### H1: Reintro cards help struggling words (from experiment log)
**Status**: Partially supported. 57% remembered on first attempt, and the "fail-then-remember" pattern for 3 words is promising. But FSRS stability remains very low for all reintroduced words. Need multi-day tracking to assess lasting impact.

### H2: Sentence diversity prevents stale repetition
**Status**: Supported. 87% of sentences shown only once. The comprehension-aware recency filter is working effectively. No sentence has been shown more than 3 times across 3 days.

### Collateral credit inflation concern (new)
**Status**: Warrants monitoring. 68% of all reviews are collateral credit (rating=3 for non-target words in understood/partial sentences). This means many words accumulate "correct" reviews passively. The 83 words at 80%+ accuracy may be inflated by collateral credit rather than genuine active recall.

---

## Key Concerns

1. **Persistent zero-accuracy cohort**: 48 words (26% of reviewed) remain at 0% accuracy after 3 days. These need intervention beyond standard FSRS scheduling.

2. **Declining comprehension rate**: "Understood" dropped from 44% (day 1) to 22% (day 3). If this trend continues, the learner may be encountering too much difficulty.

3. **Collateral credit dominance**: 68% collateral reviews may be inflating word stability. Consider whether collateral reviews at rating=3 are appropriate for all words or if only "partial" sentences should give reduced credit.

4. **Study/textbook words underperforming**: Study-source words average 19% accuracy vs 70% for Duolingo words. The Learn mode selection algorithm may be choosing words that are too difficult, or these words need more review cycles.

5. **97 unseen words**: 34% of tracked vocabulary has never been reviewed. The 85 textbook imports need to be integrated into review sessions soon.

---

## Recommendations

1. **Leeches intervention**: Flag the 48 zero-accuracy words as "leeches" after N failures (suggest N=5). Offer targeted flashcard drills or reintro-style remediation outside the sentence review flow.

2. **Collateral credit dampening**: Consider reducing collateral credit for "partial" comprehension sentences. Currently all non-missed/non-confused words get rating=3; perhaps rating=2 (Hard) for collateral words in partial sentences would be more conservative.

3. **Session difficulty calibration**: The declining "understood" rate suggests the greedy set cover may be selecting sentences with too many due/struggling words. Consider capping the number of difficult target words per session.

4. **Textbook word integration**: The 85 textbook scan words should begin appearing in review sessions within 1-2 days. Monitor whether the sudden influx overwhelms the session assembly algorithm.

5. **Listening mode expansion**: Only 5% of reviews are in listening mode. Given the higher comprehension rate (57% understood vs 29% for reading), listening practice with well-known words could reinforce learning.

6. **Lookup-to-review correlation**: The 488 lookup events are a rich signal. Words that are frequently looked up but still reviewed as "understood" may indicate the learner relies on lookup rather than recall. Consider tracking lookup-then-rating patterns.

---

## Raw Data Appendix

### Review totals
- Total word reviews: 481
- Total sentence reviews: 125
- Total word lookups: 488
- Total interaction events: ~2,088

### FSRS card distribution (all 282 words)
- <0.5d stability: 71
- 0.5-1d: 3
- 1-3d: 91
- 3-7d: 2
- 7-30d: 8
- 30d+: 107 (mostly unseen/default cards)
